diff --git a/pyproject.toml b/pyproject.toml
index b4644a7..9f7945f 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -2,7 +2,7 @@
 name = "spd"
 version = "0.0.1"
 description = "Sparse Parameter Decomposition"
-requires-python = "==3.12"
+requires-python = ">=3.12"
 urls = { "Homepage" = "https://github.com/goodfire-ai/spd" }
 license = { text = "MIT" }
 readme = "README.md"
@@ -20,7 +20,7 @@ dependencies = [
     "matplotlib==3.9.1", # Avoid frequent pyright errors with new matplotlib versions
     "numpy",
     "python-dotenv",
-    "wandb-workspaces==0.1.12", # Need older version for workspace.from_url to work properly
+    "wandb-workspaces==0.1.12", # See https://github.com/wandb/wandb-workspaces/issues/65
     "sympy",
     "streamlit",
     "streamlit-antd-components",
@@ -49,12 +49,12 @@ include = ["spd*"]
 [tool.ruff]
 line-length = 100
 fix = true
+
+[tool.ruff.lint]
 ignore = [
     "F722", # Incompatible with jaxtyping
     "E731" # I think lambda functions are fine in several places
 ]
-
-[tool.ruff.lint]
 select = [
     # pycodestyle
     "E",
@@ -74,7 +74,7 @@ select = [
 # Enable reformatting of code snippets in docstrings.
 docstring-code-format = true
 
-[tool.ruff.isort]
+[tool.ruff.lint.isort]
 known-third-party = ["wandb"]
 
 [tool.pyright]
diff --git a/spd/data.py b/spd/data.py
index b44210c..5b2b7d5 100644
--- a/spd/data.py
+++ b/spd/data.py
@@ -1,11 +1,11 @@
 from typing import Any, ClassVar
 
 import numpy as np
-import torch
 from datasets import Dataset, IterableDataset, load_dataset
 from datasets.distributed import split_dataset_by_node
 from numpy.typing import NDArray
 from pydantic import BaseModel, ConfigDict
+from torch import Tensor
 from torch.utils.data import DataLoader
 from transformers import AutoTokenizer, PreTrainedTokenizer
 
@@ -187,7 +187,7 @@ def create_data_loader(
         # Get a sample from the dataset and check if it's tokenized and what the n_ctx is
         # Note that the dataset may be streamed, so we can't just index into it
         sample = next(iter(torch_dataset))[dataset_config.column_name]
-        assert isinstance(sample, torch.Tensor) and sample.ndim == 1, (
+        assert isinstance(sample, Tensor) and sample.ndim == 1, (
             "Expected the dataset to be tokenized."
         )
         assert len(sample) == dataset_config.n_ctx, "n_ctx does not match the tokenized length."
diff --git a/spd/experiments/lm/app.py b/spd/experiments/lm/app.py
index a9acfb2..52b88cc 100644
--- a/spd/experiments/lm/app.py
+++ b/spd/experiments/lm/app.py
@@ -120,7 +120,7 @@ def initialize(model_path: ModelPath) -> AppData:
             }
 
         # Map over the streaming dataset and return an iterator
-        return map(tokenize_and_prepare, iter(dataset))
+        return map(tokenize_and_prepare, iter(dataset))  # pyright: ignore[reportArgumentType]
 
     target_layer_names = sorted(ss_model.target_module_paths)
 
diff --git a/spd/experiments/tms/plotting.py b/spd/experiments/tms/plotting.py
index d4a0d0c..b2b7047 100644
--- a/spd/experiments/tms/plotting.py
+++ b/spd/experiments/tms/plotting.py
@@ -14,11 +14,12 @@ import matplotlib.pyplot as plt
 import numpy as np
 import numpy.typing as npt
 import torch
+import torch.nn as nn
 from jaxtyping import Float
 from matplotlib.axes import Axes
 from matplotlib.colors import Colormap
 from matplotlib.figure import Figure
-from torch import Tensor, nn
+from torch import Tensor
 
 from spd.experiments.tms.models import TMSModel
 from spd.models.component_model import ComponentModel
diff --git a/spd/experiments/tms/tms_decomposition.py b/spd/experiments/tms/tms_decomposition.py
index 2e55371..da56da3 100644
--- a/spd/experiments/tms/tms_decomposition.py
+++ b/spd/experiments/tms/tms_decomposition.py
@@ -143,6 +143,4 @@ def main(
 
 
 if __name__ == "__main__":
-    # main("spd/experiments/tms/tms_5-2_config.yaml")
-
     fire.Fire(main)
diff --git a/spd/experiments/tms/train_tms.py b/spd/experiments/tms/train_tms.py
index c43d92f..0a6f79c 100644
--- a/spd/experiments/tms/train_tms.py
+++ b/spd/experiments/tms/train_tms.py
@@ -3,7 +3,7 @@ https://colab.research.google.com/github/anthropics/toy-models-of-superposition/
 """
 
 from pathlib import Path
-from typing import Literal, Self, cast
+from typing import Literal, Self
 
 import einops
 import matplotlib.pyplot as plt
@@ -12,7 +12,7 @@ import torch
 import wandb
 from matplotlib import collections as mc
 from pydantic import BaseModel, ConfigDict, PositiveInt, model_validator
-from torch import nn
+from torch import Tensor, nn
 from tqdm import tqdm, trange
 
 from spd.experiments.tms.models import TMSModel, TMSModelConfig
@@ -65,7 +65,7 @@ def cosine_decay_lr(step: int, steps: int) -> float:
 
 def train(
     model: TMSModel,
-    dataloader: DatasetGeneratedDataLoader[tuple[torch.Tensor, torch.Tensor]],
+    dataloader: DatasetGeneratedDataLoader[tuple[Tensor, Tensor]],
     log_wandb: bool,
     importance: float,
     steps: int,
@@ -176,22 +176,20 @@ def plot_cosine_similarity_distribution(
 
 def get_model_and_dataloader(
     config: TMSTrainConfig, device: str
-) -> tuple[TMSModel, DatasetGeneratedDataLoader[tuple[torch.Tensor, torch.Tensor]]]:
+) -> tuple[TMSModel, DatasetGeneratedDataLoader[tuple[Tensor, Tensor]]]:
     model = TMSModel(config=config.tms_model_config)
     model.to(device)
     if (
         config.fixed_identity_hidden_layers or config.fixed_random_hidden_layers
     ) and model.hidden_layers is not None:
         for i in range(model.config.n_hidden_layers):
+            layer = model.hidden_layers[i]
+            assert isinstance(layer, nn.Linear)
             if config.fixed_identity_hidden_layers:
-                cast(nn.Linear, model.hidden_layers[i]).weight.data[:, :] = torch.eye(
-                    model.config.n_hidden, device=device
-                )
+                layer.weight.data[:, :] = torch.eye(model.config.n_hidden, device=device)
             elif config.fixed_random_hidden_layers:
-                cast(nn.Linear, model.hidden_layers[i]).weight.data[:, :] = torch.randn_like(
-                    cast(nn.Linear, model.hidden_layers[i]).weight
-                )
-            cast(nn.Linear, model.hidden_layers[i]).weight.requires_grad = False
+                layer.weight.data[:, :] = torch.randn_like(layer.weight)
+            layer.weight.requires_grad = False
 
     dataset = SparseFeatureDataset(
         n_features=config.tms_model_config.n_features,
diff --git a/spd/losses.py b/spd/losses.py
index 8d06efa..3824167 100644
--- a/spd/losses.py
+++ b/spd/losses.py
@@ -49,8 +49,9 @@ def calc_embedding_recon_loss(
 
         if unembed:
             assert hasattr(model.target_model, "lm_head"), "Only supports unembedding named lm_head"
-            target_out_unembed = model.target_model.lm_head(target_out)  # pyright: ignore[reportCallIssue]
-            masked_out_unembed = model.target_model.lm_head(masked_out)  # pyright: ignore[reportCallIssue]
+            assert isinstance(model.target_model.lm_head, nn.Module)
+            target_out_unembed = model.target_model.lm_head(target_out)
+            masked_out_unembed = model.target_model.lm_head(masked_out)
             loss += calc_kl_divergence_lm(pred=masked_out_unembed, target=target_out_unembed)
         else:
             loss += ((masked_out - target_out) ** 2).sum(dim=-1).mean()
diff --git a/spd/models/component_model.py b/spd/models/component_model.py
index 4b168cd..f10e76d 100644
--- a/spd/models/component_model.py
+++ b/spd/models/component_model.py
@@ -15,11 +15,11 @@ from wandb.apis.public import Run
 from spd.configs import Config
 from spd.models.components import (
     Components,
+    ComponentsOrModule,
     EmbeddingComponents,
     GateMLPs,
     GateType,
     LinearComponents,
-    ReplacedComponents,
     VectorGateMLPs,
 )
 from spd.models.sigmoids import SIGMOID_TYPES, SigmoidTypes
@@ -58,15 +58,16 @@ class ComponentModel(nn.Module):
             target_model, target_module_patterns
         )
 
-        components_or_modules = self.create_components_or_modules(
-            target_model, self.target_module_paths, C
+        # We just keep components_or_modules as a plain dict. State_dict will pick the
+        # components up because they're attached to the target_model via set_submodule
+        self.components_or_modules = self.create_components_or_modules(
+            target_model=target_model,
+            target_module_paths=self.target_module_paths,
+            C=C,
         )
+        self.gates = self.make_gates(gate_type, C, gate_hidden_dims, self.components_or_modules)
 
-        # just keep components_or_modules as a plain dict.
-        # state_dict will pick it up via the target_model
-        self.components_or_modules: dict[str, ReplacedComponents] = components_or_modules
-
-        self.gates = self.make_gates(gate_type, C, gate_hidden_dims, components_or_modules)
+        # Register the gates to ComponentModel so they appear in e.g. state_dict()
         self._gates = nn.ModuleDict({k.replace(".", "-"): v for k, v in self.gates.items()})
 
     @property
@@ -76,12 +77,19 @@ class ComponentModel(nn.Module):
     def _get_target_module_paths(
         self, model: nn.Module, target_module_patterns: list[str]
     ) -> list[str]:
+        """Find the target_module_patterns that match real modules in the target model.
+
+        e.g. `["layers.*.mlp_in"]` ->  `["layers.1.mlp_in", "layers.2.mlp_in"]`.
+        """
+
+        names_out: list[str] = []
         matched_patterns: set[str] = set()
         for name, _ in model.named_modules():
             for pattern in target_module_patterns:
                 if fnmatch.fnmatch(name, pattern):
-                    print(f"Matched {name} to {pattern}")
                     matched_patterns.add(pattern)
+                    names_out.append(name)
+
         unmatched_patterns = set(target_module_patterns) - matched_patterns
         if unmatched_patterns:
             raise ValueError(
@@ -89,16 +97,55 @@ class ComponentModel(nn.Module):
                 f"{sorted(unmatched_patterns)}"
             )
 
-        return list(matched_patterns)
+        return names_out
 
     @staticmethod
     def create_components_or_modules(
         target_model: nn.Module,
         target_module_paths: list[str],
         C: int,
-    ) -> dict[str, ReplacedComponents]:
-        """Create target components for the model."""
-        components_or_modules: dict[str, ReplacedComponents] = {}
+    ) -> dict[str, ComponentsOrModule]:
+        """Replace nn.Modules with ComponentsOrModule objects based on target_module_paths.
+
+        NOTE: This method both mutates the target_model and returns dictionary of references
+        to the newly inserted ComponentsOrModule objects.
+
+        Example:
+            >>> target_model
+            MyModel(
+                (linear): Linear(in_features=10, out_features=10, bias=True)
+            )
+            >>> target_module_paths = ["linear"]
+            >>> components_or_modules = create_components_or_modules(
+            ...     target_model,
+            ...     target_module_paths,
+            ...     C=2,
+            ... )
+            >>> print(target_model)
+            MyModel(
+                (linear): ComponentsOrModule(
+                    (original): Linear(in_features=10, out_features=10, bias=True),
+                    (components): LinearComponents(C=2, d_in=10, d_out=10, bias=True),
+                )
+            )
+            >>> print(components_or_modules)
+            {
+                "linear": ComponentsOrModule(
+                    (original): Linear(in_features=10, out_features=10, bias=True),
+                    (components): LinearComponents(C=2, d_in=10, d_out=10, bias=True),
+                ),
+            }
+
+        Args:
+            target_model: The target model to replace modules in.
+            target_module_paths: The paths to the modules to replace.
+            C: The number of components to use.
+
+        Returns:
+            A dictionary mapping module paths to the newly inserted ComponentsOrModule objects
+            within target_model.
+        """
+        components_or_modules: dict[str, ComponentsOrModule] = {}
 
         for module_path in target_module_paths:
             module = target_model.get_submodule(module_path)
@@ -106,7 +153,7 @@ class ComponentModel(nn.Module):
             if isinstance(module, nn.Linear):
                 d_out, d_in = module.weight.shape
                 component = LinearComponents(C=C, d_in=d_in, d_out=d_out, bias=module.bias)
-                component.init_from_target_weight(module.weight)
+                component.init_from_target_weight(module.weight.T)
             elif isinstance(module, nn.Embedding):
                 component = EmbeddingComponents(
                     C=C,
@@ -121,7 +168,7 @@ class ComponentModel(nn.Module):
                     f"nn.Embedding. Found type: {type(module)}"
                 )
 
-            replacement = ReplacedComponents(original=module, components=component)
+            replacement = ComponentsOrModule(original=module, components=component)
 
             target_model.set_submodule(module_path, replacement)
 
@@ -134,7 +181,7 @@ class ComponentModel(nn.Module):
         gate_type: GateType,
         C: int,
         gate_hidden_dims: list[int],
-        components_or_modules: dict[str, ReplacedComponents],
+        components_or_modules: dict[str, ComponentsOrModule],
     ) -> dict[str, nn.Module]:
         gates: dict[str, nn.Module] = {}
         for module_path, component in components_or_modules.items():
diff --git a/spd/models/components.py b/spd/models/components.py
index e0f0336..3dae49b 100644
--- a/spd/models/components.py
+++ b/spd/models/components.py
@@ -77,24 +77,25 @@ class VectorGateMLPs(nn.Module):
 
 
 class Components(ABC, nn.Module):
-    def __init__(self, C: int, rows: int, cols: int):
+    def __init__(self, C: int, v_dim: int, u_dim: int):
         """
-        Base class for all components.
+        Base class for components in a single layer (that would replace nn.Linear or nn.Embedding weight matrices).
+        Initializes matrices V (which transforms the input activations) and U (which transforms the output of in_acts @ V)"
 
         Args:
             C: Number of components
-            rows: Number of rows in the weight matrix
-            cols: Number of columns in the weight matrix
+            v_dim: Number of rows in the target weight matrix
+            u_dim: Number of columns in the target weight matrix
         """
         super().__init__()
         self.C = C
-        self.V = nn.Parameter(torch.empty(rows, C))
-        self.U = nn.Parameter(torch.empty(C, cols))
+        self.V = nn.Parameter(torch.empty(v_dim, C))
+        self.U = nn.Parameter(torch.empty(C, u_dim))
 
     @property
+    @abstractmethod
     def weight(self) -> Float[Tensor, "rows cols"]:
-        """V @ U"""
-        return einops.einsum(self.V, self.U, "rows C, C cols -> rows cols")
+        raise NotImplementedError()
 
     def init_from_target_weight(self, target_weight: Tensor) -> None:
         """Initialize the V and U matrices.
@@ -102,7 +103,12 @@ class Components(ABC, nn.Module):
         2. Take inner product with original model
         3. This gives you roughly how much overlap there is with the target model.
         4. Scale the Us by this value (we can choose either matrix)
+
+        args:
+            target_weight: The weight matrix of the original model. In the orientation of V @ U.
+            Note that this is the transpose of the orientation of the weight matrix in the original code.
         """
+        target_weight = target_weight.to(self.U.device)
 
         V = self.V
         U = self.U
@@ -114,7 +120,7 @@ class Components(ABC, nn.Module):
         U.data[:] = U.data / U.data.norm(dim=-1, keepdim=True)
 
         # Calculate inner products
-        inner = einops.einsum(U, target_weight.to(U.device), "C cols, rows cols -> C rows")
+        inner = einops.einsum(U, target_weight, "C cols, rows cols -> C rows")
         C_norms = einops.einsum(inner, V, "C rows, rows C -> C")
 
         # Scale U by the inner product.
@@ -142,14 +148,20 @@ class LinearComponents(Components):
         d_out: int,
         bias: Tensor | None = None,
     ):
-        super().__init__(C, rows=d_out, cols=d_in)  # NOTE: linear weights are (d_out, d_in)
+        super().__init__(C, v_dim=d_in, u_dim=d_out)  # NOTE: linear weights are (d_out, d_in)
         self.d_in = d_in
         self.d_out = d_out
         self.bias = bias
 
+    @property
+    @override
+    def weight(self) -> Float[Tensor, "d_out d_in"]:
+        """(V @ U).T. Transposed to match nn.Linear which uses (d_out, d_in)"""
+        return einops.einsum(self.V, self.U, "d_in C, C d_out -> d_out d_in")
+
     @override
     def get_inner_acts(self, x: Float[Tensor, "... d_in"]) -> Float[Tensor, "... d_out"]:
-        return einops.einsum(x, self.U, "... d_in, C d_in -> ... C")
+        return einops.einsum(x, self.V, "... d_in, d_in C -> ... C")
 
     @override
     def forward(
@@ -168,7 +180,8 @@ class LinearComponents(Components):
         if mask is not None:
             component_acts *= mask
 
-        out = einops.einsum(component_acts, self.V, "... C, d_out C -> ... d_out")
+        # V is (d_out, C). Multiply this way because we use (out, in) as in nn.Linear
+        out = einops.einsum(component_acts, self.U, "... C, C d_out -> ... d_out")
 
         if self.bias is not None:
             out += self.bias
@@ -185,13 +198,21 @@ class EmbeddingComponents(Components):
         vocab_size: int,
         embedding_dim: int,
     ):
-        super().__init__(C, rows=vocab_size, cols=embedding_dim)
+        super().__init__(C, v_dim=vocab_size, u_dim=embedding_dim)
         self.vocab_size: int = vocab_size
         self.embedding_dim: int = embedding_dim
 
+    @property
     @override
-    def get_inner_acts(self, x: Float[Tensor, "... d_in"]) -> Float[Tensor, "... d_out"]:
-        return einops.einsum(x, self.U, "... d_in, d_in C -> ... C")
+    def weight(self) -> Float[Tensor, "vocab_size embedding_dim"]:
+        """V @ U"""
+        return einops.einsum(
+            self.V, self.U, "vocab_size C, C embedding_dim -> vocab_size embedding_dim"
+        )
+
+    @override
+    def get_inner_acts(self, x: Int[Tensor, "..."]) -> Float[Tensor, "... C"]:
+        return self.V[x]
 
     @override
     def forward(
@@ -207,18 +228,16 @@ class EmbeddingComponents(Components):
         """
         assert x.dtype == torch.long, "x must be an integer tensor"
 
-        component_acts: Float[Tensor, "... C"] = self.V[x]
+        component_acts: Float[Tensor, "... C"] = self.get_inner_acts(x)
 
         if mask is not None:
             component_acts *= mask
 
-        out = einops.einsum(
-            component_acts, self.U, "... C, ... C embedding_dim -> ... embedding_dim"
-        )
+        out = einops.einsum(component_acts, self.U, "... C, C embedding_dim -> ... embedding_dim")
         return out
 
 
-class ReplacedComponents(nn.Module):
+class ComponentsOrModule(nn.Module):
     def __init__(
         self,
         original: nn.Linear | nn.Embedding,
diff --git a/spd/plotting.py b/spd/plotting.py
index 7890fad..f6951a2 100644
--- a/spd/plotting.py
+++ b/spd/plotting.py
@@ -247,7 +247,7 @@ def plot_subnetwork_attributions_statistics(
 
 def plot_matrix(
     ax: plt.Axes,
-    matrix: torch.Tensor,
+    matrix: Tensor,
     title: str,
     xlabel: str,
     ylabel: str,
diff --git a/spd/run_spd.py b/spd/run_spd.py
index ccb3c57..0ba92ae 100644
--- a/spd/run_spd.py
+++ b/spd/run_spd.py
@@ -100,7 +100,9 @@ def optimize(
     lr_schedule_fn = get_lr_schedule_fn(config.lr_schedule, config.lr_exponential_halflife)
     logger.info(f"Base LR scheduler created: {config.lr_schedule}")
 
-    n_params = sum(component.weight.numel() for component in model.components.values())
+    n_params = sum(
+        component.original.weight.numel() for component in model.components_or_modules.values()
+    )
 
     data_iter = iter(train_loader)
 
diff --git a/spd/user_metrics_and_figs.py.example b/spd/user_metrics_and_figs.py.example
new file mode 100644
index 0000000..f64ea47
--- /dev/null
+++ b/spd/user_metrics_and_figs.py.example
@@ -0,0 +1,73 @@
+"""User-defined metrics and figures for SPD experiments.
+
+This file provides custom metrics and visualizations that are logged during SPD optimization.
+Users can modify this file to add their own metrics and figures without changing core framework code.
+"""
+# pyright: reportUnusedParameter=false
+
+import torch
+import wandb
+from jaxtyping import Float, Int
+from matplotlib.figure import Figure
+from torch import Tensor
+
+from spd.configs import Config
+from spd.models.component_model import ComponentModel
+
+
+def compute_user_metrics(
+    model: ComponentModel,
+    causal_importances: dict[str, Float[Tensor, "... C"]],
+    unmasked_component_out: Float[Tensor, "... d_model_out"],
+    masked_component_out: Float[Tensor, "... d_model_out"],
+    target_out: Float[Tensor, "... d_model_out"],
+    batch: Int[Tensor, "... d_model_in"],
+    device: str | torch.device,
+    config: Config,
+    step: int,
+) -> dict[str, float | int | wandb.Table]:
+    """Compute custom metrics during SPD optimization.
+       Args:
+        model: The ComponentModel
+        causal_importances: Dict of causal importance tensors
+        unmasked_component_out: Output of model with all components unmasked
+        masked_component_out: Output of model with components masked by causal importances
+        target_out: Output of target model
+        batch: Current batch tensor
+        device: Device used for computation
+        config: The full configuration object
+        step: Current training step
+
+    Returns:
+        Dict mapping metric names to values (float or int or wandb.Table)
+    """
+    metrics = {}
+    return metrics
+
+
+def create_user_figures(
+    model: ComponentModel,
+    causal_importances: dict[str, Float[Tensor, "... C"]],
+    target_out: Float[Tensor, "... d_model_out"],
+    batch: Int[Tensor, "... d_model_in"],
+    device: str | torch.device,
+    config: Config,
+    step: int,
+) -> dict[str, Figure]:
+    """Create custom figures during SPD optimization.
+
+    Args:
+        model: The ComponentModel
+        causal_importances: Dict of causal importance tensors
+        target_out: Output of target model
+        batch: Current batch tensor
+        device: Device used for computation
+        config: The full configuration object
+        step: Current training step
+
+    Returns:
+        Dict mapping figure names to matplotlib Figure objects
+
+    """
+    figures = {}
+    return figures
diff --git a/spd/utils/data_utils.py b/spd/utils/data_utils.py
index 769fbad..6e0df43 100644
--- a/spd/utils/data_utils.py
+++ b/spd/utils/data_utils.py
@@ -45,7 +45,7 @@ class BatchedDataLoader(DataLoader[Q], Generic[Q]):
         super().__init__(dataset, num_workers=num_workers)
 
     @override
-    def __iter__(self) -> Iterator[tuple[torch.Tensor, torch.Tensor]]:  # pyright: ignore[reportIncompatibleMethodOverride]
+    def __iter__(self) -> Iterator[tuple[Tensor, Tensor]]:  # pyright: ignore[reportIncompatibleMethodOverride]
         for batch, label in super().__iter__():
             yield batch[0], label[0]
 
diff --git a/spd/utils/general_utils.py b/spd/utils/general_utils.py
index 72cf025..92203fb 100644
--- a/spd/utils/general_utils.py
+++ b/spd/utils/general_utils.py
@@ -40,11 +40,7 @@ COLOR_PALETTE = [
 
 def get_device() -> str:
     # NOTE: MPS returns NaNs on TMS when run. Avoiding for now.
-    return (
-        "mps"
-        if torch.backends.mps.is_available()
-        else ("cuda" if torch.cuda.is_available() else "cpu")
-    )
+    return "cuda" if torch.cuda.is_available() else "cpu"
 
 
 def set_seed(seed: int | None) -> None:
@@ -243,9 +239,9 @@ def load_pretrained(
 
 
 def extract_batch_data(
-    batch_item: dict[str, Any] | tuple[torch.Tensor, ...] | torch.Tensor,
+    batch_item: dict[str, Any] | tuple[Tensor, ...] | Tensor,
     input_key: str = "input_ids",
-) -> torch.Tensor:
+) -> Tensor:
     """Extract input data from various batch formats.
 
     This utility function handles different batch formats commonly used across the codebase:
@@ -260,7 +256,7 @@ def extract_batch_data(
     Returns:
         The input tensor extracted from the batch
     """
-    assert isinstance(batch_item, dict | tuple | torch.Tensor), (
+    assert isinstance(batch_item, dict | tuple | Tensor), (
         f"Unsupported batch format: {type(batch_item)}. Must be a dictionary, tuple, or tensor."
     )
     if isinstance(batch_item, dict):
diff --git a/spd/utils/module_utils.py b/spd/utils/module_utils.py
index 426d536..4556b07 100644
--- a/spd/utils/module_utils.py
+++ b/spd/utils/module_utils.py
@@ -43,7 +43,7 @@ def remove_grad_parallel_to_subnetwork_vecs(
 
 
 def init_param_(
-    param: torch.Tensor,
+    param: Tensor,
     fan_val: float,
     mean: float = 0.0,
     nonlinearity: str = "linear",
diff --git a/tests/test_component_model.py b/tests/test_component_model.py
index f68295a..0ce5688 100644
--- a/tests/test_component_model.py
+++ b/tests/test_component_model.py
@@ -3,10 +3,10 @@ from typing import override
 import pytest
 import torch
 from jaxtyping import Float
-from torch import nn
+from torch import Tensor, nn
 
 from spd.models.component_model import ComponentModel
-from spd.models.components import EmbeddingComponents, LinearComponents, ReplacedComponents
+from spd.models.components import ComponentsOrModule, EmbeddingComponents, LinearComponents
 
 
 class SimpleTestModel(nn.Module):
@@ -20,7 +20,7 @@ class SimpleTestModel(nn.Module):
         self.other_layer = nn.ReLU()  # Non‑target layer (should never be wrapped)
 
     @override
-    def forward(self, x: Float[torch.Tensor, "... 10"]):  # noqa: D401,E501
+    def forward(self, x: Float[Tensor, "... 10"]):  # noqa: D401,E501
         return self.linear2(self.linear1(x))
 
 
@@ -89,25 +89,30 @@ def test_replaced_modules_sets_and_restores_masks_partial(component_model: Compo
 
 
 def test_replaced_component_forward_linear_matches_modes():
-    lin = nn.Linear(6, 4, bias=True)
-    comp = LinearComponents(d_in=6, d_out=4, C=3, bias=lin.bias)
-    rep = ReplacedComponents(original=lin, components=comp)
+    B = 5
+    C = 3
+    input_dim = 6
+    output_dim = 4
 
-    x = torch.randn(5, 6)
+    original = nn.Linear(input_dim, output_dim, bias=True)
+    components = LinearComponents(d_in=input_dim, d_out=output_dim, C=3, bias=original.bias)
+    components_or_module = ComponentsOrModule(original=original, components=components)
+
+    x = torch.randn(B, input_dim)
 
     # --- Original path ---
-    rep.forward_mode = "original"
-    rep.mask = None
-    out_orig = rep(x)
-    expected_orig = lin(x)
+    components_or_module.forward_mode = "original"
+    components_or_module.mask = None
+    out_orig = components_or_module(x)
+    expected_orig = original(x)
     torch.testing.assert_close(out_orig, expected_orig, rtol=1e-4, atol=1e-5)
 
     # --- Replacement path (with mask) ---
-    rep.forward_mode = "components"
-    mask = torch.rand(5, 3)
-    rep.mask = mask
-    out_rep = rep(x)
-    expected_rep = comp(x, mask)
+    mask = torch.rand(B, C)
+    components_or_module.forward_mode = "components"
+    components_or_module.mask = mask
+    out_rep = components_or_module(x)
+    expected_rep = components(x, mask)
     torch.testing.assert_close(out_rep, expected_rep, rtol=1e-4, atol=1e-5)
 
 
@@ -118,7 +123,7 @@ def test_replaced_component_forward_embedding_matches_modes():
 
     emb = nn.Embedding(vocab_size, embedding_dim)
     comp = EmbeddingComponents(vocab_size=vocab_size, embedding_dim=embedding_dim, C=C)
-    rep = ReplacedComponents(original=emb, components=comp)
+    rep = ComponentsOrModule(original=emb, components=comp)
 
     batch_size = 4
     seq_len = 7